{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import PreTrainedModel, AutoModelForSequenceClassification, T5ForConditionalGeneration\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers import BertForSequenceClassification\n",
    "import transformers\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RMTBaseModel(torch.nn.Module):\n",
    "    def __init__(self, base_model, **rmt_kwargs):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.set_params(**rmt_kwargs)\n",
    "\n",
    "    def set_params(self, num_mem_tokens, tokenizer, **rmt_config):\n",
    "        self.rmt_config = rmt_config\n",
    "        self.extract_special_tokens(tokenizer)\n",
    "        self.extend_word_embeddings(num_mem_tokens, tokenizer)\n",
    "\n",
    "        self.segment_size = rmt_config['input_size'] - num_mem_tokens - tokenizer.num_special_tokens_to_add()\n",
    "        if 'sep_token' in tokenizer.special_tokens_map:\n",
    "            self.segment_size -= 1\n",
    "\n",
    "    def set_memory(self, input_shape):\n",
    "        memory = self.model.embeddings(self.mem_token_ids)\n",
    "        memory = memory.repeat(input_shape[0], 1, 1)\n",
    "        return memory\n",
    "\n",
    "    def extract_special_tokens(self, tokenizer):\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.special_token_ids = [tokenizer.pad_token_id]\n",
    "        for token in ['cls_token', 'sep_token', 'eos_token', 'bos_token']:\n",
    "            token_id = getattr(tokenizer, f'{token}_id')\n",
    "            if token_id is not None:\n",
    "                self.register_buffer(token, torch.tensor([token_id]))\n",
    "                self.special_token_ids.append(token_id)\n",
    "            else:\n",
    "                setattr(self, token, None)\n",
    "\n",
    "    def extend_word_embeddings(self, num_mem_tokens, tokenizer):\n",
    "            \n",
    "        vocab_size = self.model.config.vocab_size\n",
    "        extended_vocab_size = vocab_size + num_mem_tokens\n",
    "        self.num_mem_tokens = num_mem_tokens\n",
    "        self.register_buffer('mem_token_ids', torch.arange(vocab_size, vocab_size + num_mem_tokens))\n",
    "        self.model.resize_token_embeddings(extended_vocab_size)\n",
    "\n",
    "        special_tokens = tokenizer.special_tokens_map\n",
    "        mem_start_ind = int('cls_token' in special_tokens or 'bos_token' in special_tokens)\n",
    "        self.memory_position = range(mem_start_ind, mem_start_ind + num_mem_tokens)\n",
    "        self.model.embeddings = self.model.get_input_embeddings()\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "       raise NotImplementedError\n",
    "\n",
    "    def pad_and_segment(self, input_ids):\n",
    "        segmented_batch = []\n",
    "        for seq in input_ids:\n",
    "            drop_mask = torch.any(torch.stack([seq == t for t in self.special_token_ids if t is not None]), dim=0)\n",
    "            seq = seq[~drop_mask]\n",
    "            seq = seq[:self.segment_size * self.rmt_config['max_n_segments']]\n",
    "\n",
    "            align = self.rmt_config.get('segment_alignment')\n",
    "            if align in {'right', None}:\n",
    "                split_inds = (list(range(len(seq), 0, -self.segment_size)) + [0])[::-1]\n",
    "            elif align == 'left':\n",
    "                split_inds = list(range(0, len(seq), self.segment_size)) + [len(seq)]\n",
    "            elif align == 'center':\n",
    "                n_seg = math.ceil(len(seq) / self.segment_size)\n",
    "                split_inds = list(range(0, len(seq), math.ceil(len(seq) / n_seg))) + [len(seq)]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            input_segments = [seq[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "            input_segments = [self.pad_add_special_tokens(t, self.rmt_config['input_size']) for t in input_segments]\n",
    "\n",
    "            # add empty segment markers if needed\n",
    "            n_empty_segments = self.rmt_config['max_n_segments'] - len(input_segments)\n",
    "            input_segments = [None] * n_empty_segments + input_segments\n",
    "\n",
    "            segmented_batch.append(input_segments)\n",
    "\n",
    "        segmented_batch = [[sample[seg_num] for sample in segmented_batch] \\\n",
    "                            for seg_num in range(self.rmt_config['max_n_segments'])]\n",
    "        return segmented_batch\n",
    "\n",
    "    def pad_add_special_tokens(self, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def prepare_kwargs(self, segment_input_ids, kwargs):\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "        non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "        if sum(non_empty_mask) == 0:\n",
    "            return None, non_empty_mask\n",
    "            \n",
    "        input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "        inputs_embeds = self.model.embeddings(input_ids)\n",
    "\n",
    "        seg_kwargs['input_ids'] = None\n",
    "        seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "        if seg_kwargs.get('labels') is not None:\n",
    "            seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "        seg_kwargs['attention_mask'] = self.get_attention_mask(input_ids)\n",
    "        if seg_kwargs.get('token_type_ids') is not None:\n",
    "            seg_kwargs['token_type_ids'] = self.get_token_type_ids(input_ids)\n",
    "        seg_kwargs['output_hidden_states'] = True\n",
    "\n",
    "        return seg_kwargs, non_empty_mask\n",
    "\n",
    "    def process_outputs(self, model_outputs, output_attentions, output_hidden_states):\n",
    "        rmt_out = model_outputs[-1]\n",
    "\n",
    "        segment_keys = ['loss']\n",
    "        if output_attentions:\n",
    "            segment_keys.append('attentions')\n",
    "        if output_hidden_states:\n",
    "            segment_keys.append('hidden_states')\n",
    "\n",
    "        extracted = {}\n",
    "        for seg_num, out in enumerate(model_outputs):\n",
    "            for key, value in out.items():\n",
    "                if any([sk in key for sk in segment_keys]):\n",
    "                    extracted[f'{key}_{seg_num}'] = value\n",
    "\n",
    "        if self.rmt_config['sum_loss']:\n",
    "            losses = [out['loss'] for out in model_outputs]\n",
    "            extracted['loss'] = torch.stack(losses).mean(dim=0)\n",
    "\n",
    "        for key, value in extracted.items():\n",
    "            rmt_out[key] = value\n",
    "        \n",
    "        # drop unnecessary hiddens to save memory\n",
    "        if not output_hidden_states:\n",
    "            for key in rmt_out.keys():\n",
    "                if 'hidden_state' in key:\n",
    "                    rmt_out[key] = None\n",
    "\n",
    "        return rmt_out \n",
    "        \n",
    "    def get_token_type_ids(self, tensor):\n",
    "        return torch.zeros_like(tensor)\n",
    "\n",
    "    def get_attention_mask(self, tensor):\n",
    "        mask = torch.ones_like(tensor)\n",
    "        mask[tensor == self.pad_token_id] = 0\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RMTDecoderLMHead(RMTBaseModel):\n",
    "#     def set_params(self, num_mem_tokens, tokenizer, **rmt_config):\n",
    "#         self.rmt_config = rmt_config\n",
    "#         self.extract_special_tokens(tokenizer)\n",
    "#         self.create_memory(num_mem_tokens)\n",
    "\n",
    "#         self.segment_size = rmt_config['input_size'] - 2 * num_mem_tokens - tokenizer.num_special_tokens_to_add()\n",
    "#         if 'sep_token' in tokenizer.special_tokens_map:\n",
    "#             self.segment_size -= 1\n",
    "\n",
    "#     def create_memory(self, num_mem_tokens):\n",
    "#         self.num_mem_tokens = num_mem_tokens\n",
    "#         embeddings = self.model.get_input_embeddings()\n",
    "#         memory_weights = torch.randn((num_mem_tokens, self.model.config.n_embd)) * embeddings.weight.data.std()\n",
    "#         self.register_parameter('memory', torch.nn.Parameter(memory_weights, requires_grad=True))\n",
    "\n",
    "#         self.read_memory_position = range(num_mem_tokens)\n",
    "#         self.write_memory_position = range(-num_mem_tokens, 0)\n",
    "\n",
    "#     def set_memory(self, input_shape):\n",
    "#         memory = self.memory.repeat(input_shape[0], 1, 1)\n",
    "#         return memory\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "#                 inputs_embeds=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "#         kwargs = {'attention_mask': attention_mask, 'token_type_ids': token_type_ids,\n",
    "#                   'position_ids': position_ids, 'inputs_embeds': inputs_embeds,\n",
    "#                   'labels': labels, 'output_attentions': output_attentions,\n",
    "#                   'output_hidden_states': output_hidden_states, 'return_dict': return_dict,\n",
    "#                   }\n",
    "\n",
    "#         if not hasattr(self, 'memory_states') or self.memory_states is None:\n",
    "#             init_memory = self.set_memory(input_ids.shape)\n",
    "#             self.memory_states = [(None, init_memory)]\n",
    "        \n",
    "#         memory = self.memory_states[-1][1].detach()#.to(input_ids.device)\n",
    "#         memory.requires_grad = True\n",
    "\n",
    "#         segment_input_ids = self.pad_and_segment(input_ids)[0]\n",
    "#         seg_kwargs, non_empty_mask = self.prepare_kwargs(segment_input_ids, memory, kwargs)\n",
    "        \n",
    "#         labels = seg_kwargs.pop('labels')\n",
    "#         out = self.model(**seg_kwargs)\n",
    "        \n",
    "#         new_memory = out.hidden_states[-1][:, self.write_memory_position]\n",
    "#         self.memory_states.append((memory, new_memory))\n",
    "#         self.trim_memory_states()\n",
    "\n",
    "#         ### Calculate loss excluding memory \n",
    "#         lm_logits = out.logits[:, self.num_mem_tokens:-self.num_mem_tokens]\n",
    "#         # Shift so that tokens < n predict n\n",
    "#         shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "#         shift_labels = labels[..., 1:].contiguous()\n",
    "#         # Flatten the tokens\n",
    "#         loss_fct = CrossEntropyLoss()\n",
    "#         out['loss'] = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "#         return out\n",
    "\n",
    "#     def pad_add_special_tokens(self, tensor, segment_size):\n",
    "#         # pad_size = segment_size - tensor.shape[0]\n",
    "#         # if pad_size > 0:\n",
    "#         #     tensor = F.pad(tensor, (0, pad_size))\n",
    "#         return tensor\n",
    "    \n",
    "#     def prepare_kwargs(self, segment_input_ids, memory, kwargs):\n",
    "#         seg_kwargs = dict(**kwargs)\n",
    "#         non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "#         if sum(non_empty_mask) == 0:\n",
    "#             return None, non_empty_mask\n",
    "            \n",
    "#         input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "#         inputs_embeds = self.model.get_input_embeddings()(input_ids)\n",
    "#         inputs_embeds = torch.cat([memory, inputs_embeds, memory], dim=1)\n",
    "\n",
    "#         seg_kwargs['input_ids'] = None\n",
    "#         seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "#         if seg_kwargs.get('labels') is not None:\n",
    "#             seg_kwargs['labels'] = seg_kwargs['labels'][non_empty_mask]\n",
    "#         seg_kwargs['attention_mask'] = self.get_attention_mask(inputs_embeds)\n",
    "#         # if seg_kwargs.get('token_type_ids') is not None:\n",
    "#         #     seg_kwargs['token_type_ids'] = self.get_token_type_ids(inputs_embeds)\n",
    "#         seg_kwargs['output_hidden_states'] = True\n",
    "\n",
    "#         return seg_kwargs, non_empty_mask\n",
    "    \n",
    "#     def get_attention_mask(self, tensor):\n",
    "#         mask = torch.ones(*tensor.shape[:2], dtype=torch.int64).to(tensor.device)\n",
    "#         mask[tensor == self.pad_token_id] = 0\n",
    "#         return mask\n",
    "\n",
    "#     def train(self, *args, **kwargs):\n",
    "#         self.memory_states = None\n",
    "#         super().train(*args, **kwargs)\n",
    "\n",
    "#     def eval(self, *args, **kwargs):\n",
    "#         self.memory_states = None\n",
    "#         super().eval(*args, **kwargs)\n",
    "\n",
    "#     def trim_memory_states(self):\n",
    "#         k2 = self.rmt_config.get('k2')\n",
    "#         if not k2 or k2 == -1:\n",
    "#             return \n",
    "#         while len(self.memory_states) > k2:\n",
    "#             del self.memory_states[0]\n",
    "\n",
    "#     def truncated_backward(self, k1, k2):\n",
    "#         memory_states = self.memory_states\n",
    "#         if k1 != -1:\n",
    "#             raise NotImplementedError\n",
    "        \n",
    "#         for i in range(k2 - 1 if k2 != -1 else len(memory_states)):\n",
    "#             curr_grad = memory_states[-i-1][0].grad\n",
    "#             memory_states[-i-2][1].backward(curr_grad, retain_graph=False)#k2>2)\n",
    "\n",
    "#             # if we get all the way back to the \"init_memory\", stop\n",
    "#             if memory_states[-i-2][0] is None:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import CrossEntropyLoss\n",
    "# from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
    "\n",
    "# class RMTDecoderLMHeadMultiSeg(RMTBaseModel):\n",
    "#     def set_params(self, num_mem_tokens, tokenizer, **rmt_config):\n",
    "#         self.rmt_config = rmt_config\n",
    "#         self.extract_special_tokens(tokenizer)\n",
    "#         self.create_memory(num_mem_tokens)\n",
    "\n",
    "#         self.segment_size = rmt_config['input_size'] - 2 * num_mem_tokens - tokenizer.num_special_tokens_to_add()\n",
    "#         if 'sep_token' in tokenizer.special_tokens_map:\n",
    "#             self.segment_size -= 1\n",
    "\n",
    "#     def create_memory(self, num_mem_tokens):\n",
    "#         self.num_mem_tokens = num_mem_tokens\n",
    "#         embeddings = self.model.get_input_embeddings()\n",
    "#         memory_weights = torch.randn((num_mem_tokens, self.model.config.n_embd)) * embeddings.weight.data.std()\n",
    "#         self.register_parameter('memory', torch.nn.Parameter(memory_weights, requires_grad=True))\n",
    "\n",
    "#         self.read_memory_position = range(num_mem_tokens)\n",
    "#         self.write_memory_position = range(-num_mem_tokens, 0)\n",
    "\n",
    "#     def set_memory(self, input_shape):\n",
    "#         if self.training or not hasattr(self, 'memory_state'):\n",
    "#             memory = self.memory.repeat(input_shape[0], 1, 1)\n",
    "#         else:\n",
    "#             memory = self.memory_state[:input_shape[0]]\n",
    "#         return memory\n",
    "    \n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "#                 inputs_embeds=None, labels=None, labels_mask=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "#         kwargs = {'attention_mask': attention_mask, 'token_type_ids': token_type_ids,\n",
    "#                   'position_ids': position_ids, 'inputs_embeds': inputs_embeds,\n",
    "#                   'labels_mask': labels_mask, #'pos_weight': pos_weight,\n",
    "#                   'labels': labels, 'output_attentions': output_attentions,\n",
    "#                   'output_hidden_states': output_hidden_states, 'return_dict': return_dict,\n",
    "#                   }\n",
    "\n",
    "#         memory = self.set_memory(input_ids.shape)\n",
    "#         segmented = self.pad_and_segment(input_ids, labels)\n",
    "\n",
    "#         base_model_outputs = []\n",
    "#         for seg_num, segment in enumerate(zip(*segmented)):                \n",
    "#             if self.rmt_config['bptt_depth'] != -1:\n",
    "#                 raise NotImplementedError\n",
    "\n",
    "#             seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, memory, kwargs)\n",
    "#             if sum(non_empty_mask) == 0:\n",
    "#                 continue\n",
    "            \n",
    "#             seg_kwargs['inputs_embeds'][:, self.read_memory_position] = memory[non_empty_mask]\n",
    "#             seg_kwargs['inputs_embeds'][:, self.write_memory_position] = memory[non_empty_mask]\n",
    "#             out = self.model(**seg_kwargs)\n",
    "#             base_model_outputs.append(out)\n",
    "            \n",
    "#             memory[non_empty_mask] = out.hidden_states[-1][:, self.write_memory_position]\n",
    "\n",
    "#         self.memory_state = memory\n",
    "#         if self.training:\n",
    "#             del self.memory_state\n",
    "#         return base_model_outputs\n",
    "#         out = self.process_outputs(base_model_outputs, kwargs)\n",
    "#         return out\n",
    "    \n",
    "#     def pad_and_segment(self, input_ids, labels=None):\n",
    "#         segmented_batch = []\n",
    "#         segmented_batch_labels = []\n",
    "\n",
    "#         if labels is None:\n",
    "#             labels = [None] * input_ids.shape[0]\n",
    "#         batch_labels = labels\n",
    "\n",
    "#         for seq, labels in zip(input_ids, batch_labels):\n",
    "#             # if seq.shape[0] != self.segment_size * self.rmt_config['max_n_segments']:\n",
    "#             #     raise(ValueError(f\"Inputs shape {input_ids.shape} does not match {self.segment_size}*{self.rmt_config['max_n_segments']}\"))\n",
    "#             # if labels is not None:\n",
    "#             #     labels = labels[:self.segment_size * self.rmt_config['max_n_segments']]\n",
    "\n",
    "#             align = self.rmt_config.get('segment_alignment')\n",
    "#             if align in {'right', None}:\n",
    "#                 split_inds = (list(range(len(seq), 0, -self.segment_size)) + [0])[::-1]\n",
    "#             elif align == 'left':\n",
    "#                 split_inds = list(range(0, len(seq), self.segment_size)) + [len(seq)]\n",
    "#             elif align == 'center':\n",
    "#                 n_seg = math.ceil(len(seq) / self.segment_size)\n",
    "#                 split_inds = list(range(0, len(seq), math.ceil(len(seq) / n_seg))) + [len(seq)]\n",
    "#             else:\n",
    "#                 raise NotImplementedError\n",
    "\n",
    "#             input_segments = [seq[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "#             # add empty segment markers if needed\n",
    "#             n_empty_segments = self.rmt_config['max_n_segments'] - len(input_segments)\n",
    "#             input_segments = [None] * n_empty_segments + input_segments\n",
    "#             segmented_batch.append(input_segments)\n",
    "\n",
    "#             if labels is not None:\n",
    "#                 labels_segments = [labels[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "#                 labels_segments = [None] * n_empty_segments + labels_segments\n",
    "#                 segmented_batch_labels.append(labels_segments)\n",
    "\n",
    "#         segmented_batch = [[sample[seg_num] for sample in segmented_batch]\n",
    "#                            for seg_num in range(self.rmt_config['max_n_segments'])]\n",
    "#         segmented_batch_labels = [[sample[seg_num] for sample in segmented_batch_labels]\n",
    "#                                   for seg_num in range(self.rmt_config['max_n_segments'])]\n",
    "\n",
    "#         return segmented_batch, segmented_batch_labels\n",
    "\n",
    "#     def prepare_kwargs(self, segment, memory, kwargs):\n",
    "#         segment_input_ids, segment_labels = segment\n",
    "#         seg_kwargs = dict(**kwargs)\n",
    "#         non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "#         if sum(non_empty_mask) == 0:\n",
    "#             return None, non_empty_mask\n",
    "\n",
    "#         input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "#         inputs_embeds = self.model.get_input_embeddings()(input_ids)\n",
    "#         inputs_embeds = torch.cat([memory, inputs_embeds, memory], dim=1)\n",
    "\n",
    "#         seg_kwargs['input_ids'] = None\n",
    "#         seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "#         seg_kwargs['attention_mask'] = self.get_attention_mask(inputs_embeds)\n",
    "#         seg_kwargs['output_hidden_states'] = True\n",
    "#         if seg_kwargs['labels'] is not None:\n",
    "#             labels = torch.stack([el for el, m in zip(segment_labels, non_empty_mask) if m])\n",
    "#             memory_labels = torch.ones((labels.shape[0], self.num_mem_tokens), dtype=labels.dtype, device=labels.device) * -100\n",
    "#             seg_kwargs['labels'] = torch.cat((memory_labels, labels, memory_labels), dim=1)\n",
    "#             seg_kwargs['labels'][:, self.num_mem_tokens] = -100\n",
    "#         seg_kwargs.pop('labels_mask')\n",
    "\n",
    "#         return seg_kwargs, non_empty_mask\n",
    "    \n",
    "#     def get_attention_mask(self, tensor):\n",
    "#         mask = torch.ones(*tensor.shape[:2], dtype=torch.int64).to(tensor.device)\n",
    "#         mask[tensor == self.pad_token_id] = 0\n",
    "#         return mask\n",
    "    \n",
    "#     def process_outputs(self, model_outputs, kwargs):\n",
    "#         full_logits = torch.cat([o.logits[:, self.num_mem_tokens:-self.num_mem_tokens] for o in model_outputs], dim=1)\n",
    "#         truncated_hs = [[lh[:, self.num_mem_tokens:-self.num_mem_tokens] for lh in o.hidden_states] for o in model_outputs]\n",
    "#         full_hidden_states = tuple([torch.cat(layer_hs, dim=1) for layer_hs in zip(*truncated_hs)])\n",
    "#         full_labels = kwargs.get('labels')\n",
    "\n",
    "#         rmt_out = CausalLMOutputWithCrossAttentions()\n",
    "#         if kwargs.get('labels') is not None:\n",
    "#             # Shift so that tokens < n predict n\n",
    "#             shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "#             shift_labels = full_labels[..., 1:].contiguous()\n",
    "\n",
    "#             # if full_labels.shape[1] != self.segment_size * self.rmt_config['max_n_segments']:\n",
    "#             #     raise(ValueError(f\"Labels shape {full_labels.shape} does not match {self.segment_size}*{self.rmt_config['max_n_segments']}\"))\n",
    "#             # Flatten the tokens\n",
    "#             loss_fct = CrossEntropyLoss(reduction='none')\n",
    "#             loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "#             labels_mask = kwargs.get('labels_mask')\n",
    "#             if labels_mask is None:\n",
    "#                 rmt_out['loss'] = loss.mean()\n",
    "#             else:\n",
    "#                 shift_mask = labels_mask[..., 1:].contiguous()\n",
    "#                 rmt_out['loss'] = loss[shift_mask.view(-1)].mean()\n",
    "\n",
    "#         rmt_out['logits'] = full_logits\n",
    "#         segment_keys = ['loss', 'logits']\n",
    "#         if kwargs.get('output_attentions'):\n",
    "#             segment_keys.append('attentions')\n",
    "#         if kwargs.get('output_hidden_states'):\n",
    "#             segment_keys.append('hidden_states')\n",
    "#             rmt_out['hidden_states'] = full_hidden_states\n",
    "\n",
    "#         for seg_num, out in enumerate(model_outputs):\n",
    "#             for key, value in out.items():\n",
    "#                 if any([sk in key for sk in segment_keys]):\n",
    "#                     rmt_out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "#         return rmt_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
    "\n",
    "class RMTDecoderLMHeadMultiSeg(RMTBaseModel):\n",
    "    def set_params(self, num_mem_tokens, tokenizer, **rmt_config):\n",
    "        self.rmt_config = rmt_config\n",
    "        self.extract_special_tokens(tokenizer)\n",
    "        self.create_memory(num_mem_tokens)\n",
    "\n",
    "        self.segment_size = rmt_config['input_size'] - 2 * num_mem_tokens - tokenizer.num_special_tokens_to_add()\n",
    "        if 'sep_token' in tokenizer.special_tokens_map:\n",
    "            self.segment_size -= 1\n",
    "\n",
    "    def create_memory(self, num_mem_tokens):\n",
    "        self.num_mem_tokens = num_mem_tokens\n",
    "        embeddings = self.model.get_input_embeddings()\n",
    "        memory_weights = torch.randn((num_mem_tokens, self.model.config.n_embd)) * embeddings.weight.data.std()\n",
    "        self.register_parameter('memory', torch.nn.Parameter(memory_weights, requires_grad=True))\n",
    "\n",
    "        self.read_memory_position = range(num_mem_tokens)\n",
    "        self.write_memory_position = range(-num_mem_tokens, 0)\n",
    "\n",
    "    def set_memory(self, input_shape):\n",
    "        create_memory = self.training \\\n",
    "                        or self.rmt_config.get('reinit_mem_each_fwd') \\\n",
    "                        or not hasattr(self, 'memory_state') \\\n",
    "                        or self.rmt_config['max_n_segments'] == 1 \n",
    "        if create_memory:\n",
    "            memory = self.memory.repeat(input_shape[0], 1, 1)\n",
    "        else:\n",
    "            memory = self.memory_state[:input_shape[0]]\n",
    "        return memory\n",
    "    \n",
    "    def detach_memory(self, seg_num):\n",
    "        k2, max_n_segments = self.rmt_config.get('k2'), self.rmt_config.get('max_n_segments')\n",
    "        if seg_num == 0 \\\n",
    "            or k2 in {-1, None} \\\n",
    "            or seg_num + k2 > max_n_segments:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
    "                inputs_embeds=None, labels=None, labels_mask=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "        kwargs = {'attention_mask': attention_mask, 'token_type_ids': token_type_ids,\n",
    "                  'position_ids': position_ids, 'inputs_embeds': inputs_embeds,\n",
    "                  'labels_mask': labels_mask, #'pos_weight': pos_weight,\n",
    "                  'labels': labels, 'output_attentions': output_attentions,\n",
    "                  'output_hidden_states': output_hidden_states, 'return_dict': return_dict,\n",
    "                  }\n",
    "\n",
    "        memory = self.set_memory(input_ids.shape)\n",
    "        segmented = self.pad_and_segment(input_ids, labels)\n",
    "\n",
    "        base_model_outputs = []\n",
    "        for seg_num, segment in enumerate(zip(*segmented)):\n",
    "\n",
    "            seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, memory, kwargs)\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "            \n",
    "            if self.detach_memory(seg_num):\n",
    "                memory = memory.detach()\n",
    "\n",
    "            seg_kwargs['inputs_embeds'][:, self.read_memory_position] = memory[non_empty_mask]\n",
    "            seg_kwargs['inputs_embeds'][:, self.write_memory_position] = memory[non_empty_mask]\n",
    "            out = self.model(**seg_kwargs)\n",
    "            base_model_outputs.append(out)\n",
    "            \n",
    "            memory[non_empty_mask] = out.hidden_states[-1][:, self.write_memory_position]\n",
    "\n",
    "        self.memory_state = memory\n",
    "        # return (base_model_outputs, kwargs)\n",
    "        out = self.process_outputs(base_model_outputs, kwargs)\n",
    "        return out\n",
    "    \n",
    "    def pad_and_segment(self, input_ids, labels=None):\n",
    "        segmented_batch = []\n",
    "        segmented_batch_labels = []\n",
    "\n",
    "        if labels is None:\n",
    "            labels = [None] * input_ids.shape[0]\n",
    "        batch_labels = labels\n",
    "        for seq, labels in zip(input_ids, batch_labels):\n",
    "\n",
    "            align = self.rmt_config.get('segment_alignment')\n",
    "            if align in {'right', None}:\n",
    "                split_inds = (list(range(len(seq), 0, -self.segment_size)) + [0])[::-1]\n",
    "            elif align == 'left':\n",
    "                split_inds = list(range(0, len(seq), self.segment_size)) + [len(seq)]\n",
    "            elif align == 'center':\n",
    "                n_seg = math.ceil(len(seq) / self.segment_size)\n",
    "                split_inds = list(range(0, len(seq), math.ceil(len(seq) / n_seg))) + [len(seq)]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            input_segments = [seq[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "            # add empty segment markers if needed\n",
    "            n_empty_segments = self.rmt_config['max_n_segments'] - len(input_segments)\n",
    "            input_segments = [None] * n_empty_segments + input_segments\n",
    "            segmented_batch.append(input_segments)\n",
    "\n",
    "            if labels is not None:\n",
    "                labels_segments = [labels[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "                labels_segments = [None] * n_empty_segments + labels_segments\n",
    "                segmented_batch_labels.append(labels_segments)\n",
    "\n",
    "        segmented_batch = [[sample[seg_num] for sample in segmented_batch]\n",
    "                           for seg_num in range(self.rmt_config['max_n_segments'])]\n",
    "        segmented_batch_labels = [[sample[seg_num] for sample in segmented_batch_labels]\n",
    "                                  for seg_num in range(self.rmt_config['max_n_segments'])]\n",
    "\n",
    "        return segmented_batch, segmented_batch_labels\n",
    "\n",
    "    def prepare_kwargs(self, segment, memory, kwargs):\n",
    "        segment_input_ids, segment_labels = segment\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "        non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "        if sum(non_empty_mask) == 0:\n",
    "            return None, non_empty_mask\n",
    "\n",
    "        input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "        inputs_embeds = self.model.get_input_embeddings()(input_ids)\n",
    "        inputs_embeds = torch.cat([memory, inputs_embeds, memory], dim=1)\n",
    "\n",
    "        seg_kwargs['input_ids'] = None\n",
    "        seg_kwargs['inputs_embeds'] = inputs_embeds\n",
    "        seg_kwargs['attention_mask'] = self.get_attention_mask(inputs_embeds)\n",
    "        seg_kwargs['output_hidden_states'] = True\n",
    "        if seg_kwargs['labels'] is not None:\n",
    "            labels = torch.stack([el for el, m in zip(segment_labels, non_empty_mask) if m])\n",
    "            memory_labels = torch.ones((labels.shape[0], self.num_mem_tokens), dtype=labels.dtype, device=labels.device) * -100\n",
    "            seg_kwargs['labels'] = torch.cat((memory_labels, labels, memory_labels), dim=1)\n",
    "            seg_kwargs['labels'][:, self.num_mem_tokens] = -100\n",
    "        seg_kwargs.pop('labels_mask')\n",
    "\n",
    "        return seg_kwargs, non_empty_mask\n",
    "    \n",
    "    def get_attention_mask(self, tensor):\n",
    "        mask = torch.ones(*tensor.shape[:2], dtype=torch.int64).to(tensor.device)\n",
    "        mask[tensor == self.pad_token_id] = 0\n",
    "        return mask\n",
    "    \n",
    "    def process_outputs(self, model_outputs, kwargs):\n",
    "        full_logits = torch.cat([o.logits[:, self.num_mem_tokens:-self.num_mem_tokens] for o in model_outputs], dim=1)\n",
    "        truncated_hs = [[lh[:, self.num_mem_tokens:-self.num_mem_tokens] for lh in o.hidden_states] for o in model_outputs]\n",
    "        full_hidden_states = tuple([torch.cat(layer_hs, dim=1) for layer_hs in zip(*truncated_hs)])\n",
    "\n",
    "        rmt_out = CausalLMOutputWithCrossAttentions()\n",
    "        full_labels = kwargs.get('labels')\n",
    "        if full_labels is not None:\n",
    "            shift_labels = full_labels[..., 1:].contiguous()\n",
    "            shift_logits = full_logits[..., :-1, :].contiguous()\n",
    "            flat_labels = shift_labels.view(-1)\n",
    "            flat_logits = shift_logits.view(-1, shift_logits.size(-1))\n",
    "            \n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            labels_mask = kwargs.get('labels_mask')\n",
    "            if labels_mask is not None:\n",
    "                shift_mask = labels_mask[..., :-1].contiguous()\n",
    "                flat_labels = flat_labels[shift_mask.view(-1)]\n",
    "                flat_logits = flat_logits[shift_mask.view(-1)]\n",
    "                \n",
    "            rmt_out['loss'] = loss_fct(flat_logits, flat_labels)\n",
    "\n",
    "        rmt_out['logits'] = full_logits\n",
    "        segment_keys = ['loss', 'logits']\n",
    "        if kwargs.get('output_attentions'):\n",
    "            segment_keys.append('attentions')\n",
    "        if kwargs.get('output_hidden_states'):\n",
    "            segment_keys.append('hidden_states')\n",
    "            rmt_out['hidden_states'] = full_hidden_states\n",
    "\n",
    "        for seg_num, out in enumerate(model_outputs):\n",
    "            for key, value in out.items():\n",
    "                if any([sk in key for sk in segment_keys]):\n",
    "                    rmt_out[f'{key}_{seg_num}'] = value\n",
    "\n",
    "        return rmt_out "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_segments = 1\n",
    "# num_mem_tokens = 2\n",
    "# device = torch.device(3)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model_name = 'gpt2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "rmt_config = {'num_mem_tokens': 1, \n",
    "                'max_n_segments': 5,\n",
    "               #  'segment_alignment': 'right',\n",
    "                'tokenizer': tokenizer,\n",
    "               #  'memory_layers': 'all', \n",
    "               #  'share_memory_layers': True,\n",
    "               #  'reconstruction_loss_coef': 0.1,\n",
    "                'offset_position_ids': True,\n",
    "                'k1': -1, 'k2': 3,\n",
    "                'segment_ordering': 'regular',\n",
    "                'input_size': 128, \n",
    "                'bptt_depth': -1, \n",
    "                'sum_loss': False,\n",
    "             }\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "rmt = RMTDecoderLMHeadMultiSeg(base_model, **rmt_config)\n",
    "# rmt2 = RMTEncoderForTokenClassification(base_model, **rmt_config)\n",
    "\n",
    "# base_model3 = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# rmt_offset = RMTDecoderLMHead(base_model3, **rmt_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç±´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n"
     ]
    }
   ],
   "source": [
    "for n, p in rmt.named_parameters():\n",
    "    if 'memory' in n:\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt.eval()\n",
    "rmt.train()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch['input_ids'].clone()#[:, :512]\n",
    "labels = batch['labels'].clone()#[:, :512]\n",
    "\n",
    "labels_mask = batch['labels_mask']\n",
    "# rmt_out_0 = rmt(input_ids, labels=labels, labels_mask=labels_mask, output_hidden_states=True, output_attentions=True)\n",
    "# rmt_out.loss\n",
    "kwargs = dict(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmt_out = rmt(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loss', tensor(2.7514, grad_fn=<NllLossBackward>)),\n",
       " ('loss_0', tensor(2.5994, grad_fn=<NllLossBackward>)),\n",
       " ('loss_1', tensor(2.7056, grad_fn=<NllLossBackward>)),\n",
       " ('loss_2', tensor(2.5862, grad_fn=<NllLossBackward>)),\n",
       " ('loss_3', tensor(2.7514, grad_fn=<NllLossBackward>))]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, rmt_out[key]) for key in rmt_out if 'loss' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loss', tensor(11.3409, grad_fn=<NllLossBackward>)),\n",
       " ('loss_0', tensor(2.9731, grad_fn=<NllLossBackward>)),\n",
       " ('loss_1', tensor(2.6483, grad_fn=<NllLossBackward>)),\n",
       " ('loss_2', tensor(2.8106, grad_fn=<NllLossBackward>)),\n",
       " ('loss_3', tensor(2.6017, grad_fn=<NllLossBackward>))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[(key, rmt_out[key]) for key in rmt_out if 'loss' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt_path = \"../../runs/lm_long/wikitext-2-v1/gpt2/lr5e-05_linear_adamw_wd1e-03_630-128-5x128_mem1_bs32_regular_bptt-5_from_cpt_4-5/run_1/model_best.pth\"\n",
    "cpt = torch.load(cpt_path, map_location='cpu')\n",
    "rmt.load_state_dict(cpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = valid_batch['input_ids'].clone()#[:, :512]\n",
    "# labels = valid_batch['labels'].clone()#[:, :512]\n",
    "# labels_mask = None\n",
    "# kwargs = dict(**valid_batch)\n",
    "# kwargs['labels_mask'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 432])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_memory(self, seg_num):\n",
    "    k2, max_n_segments = self.rmt_config.get('k2'), self.rmt_config.get('max_n_segments')\n",
    "    if seg_num == 0 \\\n",
    "        or k2 in {-1, None} \\\n",
    "        or seg_num + k2 > max_n_segments:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_num, k2, detach_memory 0 3 False\n",
      "seg_num, k2, detach_memory 1 3 True\n",
      "seg_num, k2, detach_memory 2 3 False\n",
      "seg_num, k2, detach_memory 3 3 False\n"
     ]
    }
   ],
   "source": [
    "self = rmt\n",
    "memory = self.set_memory(input_ids.shape)\n",
    "segmented = self.pad_and_segment(input_ids, labels)\n",
    "\n",
    "base_model_outputs = []\n",
    "for seg_num, segment in enumerate(zip(*segmented)):                \n",
    "\n",
    "    seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, memory, kwargs)\n",
    "    if sum(non_empty_mask) == 0:\n",
    "        # raise(ValueError('nonemptymask is zero'))\n",
    "        continue\n",
    "    \n",
    "    print('seg_num, k2, detach_memory', seg_num, self.rmt_config.get('k2'), detach_memory(self, seg_num))\n",
    "    if detach_memory(self, seg_num):\n",
    "        memory = memory.detach()\n",
    "\n",
    "    seg_kwargs['inputs_embeds'][:, self.read_memory_position] = memory[non_empty_mask]\n",
    "    seg_kwargs['inputs_embeds'][:, self.write_memory_position] = memory[non_empty_mask]\n",
    "    out = self.model(**seg_kwargs)\n",
    "    base_model_outputs.append(out)\n",
    "    \n",
    "    memory[non_empty_mask] = out.hidden_states[-1][:, self.write_memory_position]\n",
    "\n",
    "self.memory_state = memory\n",
    "# return (base_model_outputs, kwargs)\n",
    "out = self.process_outputs(base_model_outputs, kwargs)\n",
    "# return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.9269, grad_fn=<NllLossBackward>),\n",
       " tensor(10.3476, grad_fn=<NllLossBackward>),\n",
       " tensor(10.0047, grad_fn=<NllLossBackward>),\n",
       " tensor(11.6276, grad_fn=<NllLossBackward>))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_outputs[0].loss, base_model_outputs[1].loss, base_model_outputs[2].loss, base_model_outputs[3].loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [torch.ones(8) * i for i in range(1, 4)]\n",
    "memory = torch.nn.Parameter(torch.ones(2) * 5, requires_grad=True)\n",
    "ws = [torch.nn.Parameter(torch.ones(10) * 2, requires_grad=True)] * 3\n",
    "# w = torch.nn.Parameter(torch.ones(10) * 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, k2, max_n_segments 0 1 3 False\n",
      "i, k2, max_n_segments 1 1 3 True\n",
      "i, k2, max_n_segments 2 1 3 True\n"
     ]
    }
   ],
   "source": [
    "mem = memory.repeat(1)\n",
    "\n",
    "outputs = []\n",
    "losses = []\n",
    "k2 = 1\n",
    "for i, (seg, w) in enumerate(zip(segments, ws)):\n",
    "    print('i, k2, max_n_segments', i,  k2, len(segments),  i + k2 <= len(segments) and i != 0)\n",
    "    if i + k2 <= len(segments) and i != 0:\n",
    "        mem = mem.detach()\n",
    "        # inp = torch.cat((mem.detach(), seg))\n",
    "    # else:\n",
    "        # inp = torch.cat((mem, seg))\n",
    "    inp = torch.cat((mem, seg))\n",
    "    out = inp.T + w\n",
    "    mem = out[:2]\n",
    "    loss = out.mean()\n",
    "    \n",
    "    outputs.append(out)\n",
    "    losses.append(loss)\n",
    "\n",
    "total_loss = torch.cat(outputs)[-10:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.grad for w in ws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([0.3000, 0.3000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.3000, 0.3000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.3000, 0.3000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000])],\n",
       " tensor([0.1000, 0.1000]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k2 = 3\n",
    "[w.grad for w in ws], memory.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([0.2000, 0.2000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.2000, 0.2000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.2000, 0.2000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000])],\n",
       " tensor([0., 0.]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k2 = 2\n",
    "[w.grad for w in ws], memory.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000]),\n",
       "  tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "          0.1000])],\n",
       " tensor([0., 0.]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k2 = 1\n",
    "[w.grad for w in ws], memory.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k2 = 0\n",
    "# [w.grad for w in ws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1871387/516110708.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  mem.grad, memory.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor([0.1000, 0.1000]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem.grad, memory.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " tensor([2., 2., 2., 2., 2., 2., 2., 2.]),\n",
       " tensor([3., 3., 3., 3., 3., 3., 3., 3.])]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'hidden_states', 'loss_0', 'logits_0', 'hidden_states_0', 'attentions_0'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 51, 50257]), 13, torch.Size([1, 51, 768]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmt_out.logits.shape, len(rmt_out.hidden_states), rmt_out.hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "max_n_segments = 4\n",
    "input_size = 128\n",
    "num_mem_tokens = 1\n",
    "\n",
    "input_seq_len = target_seq_len = max_n_segments * (input_size - 2 * num_mem_tokens)\n",
    "batch_size = 2\n",
    "\n",
    "args = Holder\n",
    "args.max_n_segments = max_n_segments\n",
    "args.target_seq_len = target_seq_len\n",
    "args.input_seq_len = input_seq_len\n",
    "args.input_prefix = ''\n",
    "args.block_size = None\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/cryptography/hazmat/backends/openssl/x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  warnings.warn(\n",
      "Found cached dataset wikitext (/home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf748b14aba4f0883250252b5f3d404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lm_experiments_tools.lm_datasets import *\n",
    "raw_datasets = datasets.load_dataset('wikitext', 'wikitext-2-v1')\n",
    "# train_dataset, _ = get_lm_datasets(raw_datasets, tokenizer, block_size=args.input_seq_len)\n",
    "# _, valid_dataset = get_lm_datasets(raw_datasets, tokenizer, block_size=input_size - 2 * num_mem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-389b922bfc5fe729.arrow\n",
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6067a66e735cfbb1.arrow\n",
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-941845a5470f2db7.arrow\n",
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b4e1ff576225fa59.arrow\n",
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-3f80d227394578e9.arrow\n",
      "Loading cached processed dataset at /home/bulatov/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-84b71aa0796f03ec.arrow\n"
     ]
    }
   ],
   "source": [
    "block_size = input_size - 2 * num_mem_tokens\n",
    "history_size = args.input_seq_len - block_size\n",
    "\n",
    "column_names = raw_datasets[\"train\"].column_names\n",
    "text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[text_column_name])\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "def group_texts(examples, block_size, history_size=None):\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    if history_size is None:\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            k: [t[max({0, i - history_size}) : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].map(lambda x: group_texts(x, block_size, history_size), \n",
    "                                        batched=True, desc=f\"Grouping train in chunks of {block_size} and history {history_size}\")\n",
    "valid_dataset = tokenized_datasets[\"validation\"].map(lambda x: group_texts(x, block_size), \n",
    "                                        batched=True, desc=f\"Grouping valid in chunks of {block_size}\")\n",
    "test_dataset = tokenized_datasets[\"test\"].map(lambda x: group_texts(x, block_size), \n",
    "                                        batched=True, desc=f\"Grouping test in chunks of {block_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19244"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 126, 126)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0]['input_ids']), len(valid_dataset[0]['input_ids']), len(test_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 126, 126)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[1]['input_ids']), len(valid_dataset[1]['input_ids']), len(test_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 126, 126)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[2]['input_ids']), len(valid_dataset[2]['input_ids']), len(test_dataset[2]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385, 37, 8)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[-1]['input_ids']), len(valid_dataset[-1]['input_ids']), len(test_dataset[-1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "id_pad_value = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(b['input_ids'][::-1]) for b in batch]\n",
    "    labels = [torch.tensor(b['labels'][::-1]) for b in batch]\n",
    "    attention_mask = [torch.tensor(b['attention_mask'][::-1]) for b in batch]\n",
    "    input_ids = pad_sequence(input_ids, padding_value=id_pad_value).T.flip(1)\n",
    "    labels = pad_sequence(labels, padding_value=-100).T.flip(1)\n",
    "    attention_mask = pad_sequence(attention_mask, padding_value=0).T.flip(1)\n",
    "\n",
    "    collated = {'input_ids': input_ids,\n",
    "                'labels': labels, \n",
    "                'attention_mask': attention_mask}\n",
    "    \n",
    "    if input_ids.shape[1] != block_size:\n",
    "        labels_mask = torch.ones_like(input_ids, dtype=bool)\n",
    "        labels_mask[:, :-block_size] = False\n",
    "        collated['labels_mask'] = labels_mask\n",
    "    \n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader for RMT\n",
    "# batch sample i is a continuation of sample i of the previous batch\n",
    "class alignedDataLoader(DataLoader):\n",
    "    def __iter__(self):\n",
    "        # all_inds = np.arange(len(self.dataset))\n",
    "        all_inds = np.arange(len(self.dataset) // self.batch_size * batch_size)\n",
    "        all_inds = all_inds.reshape(batch_size, -1)\n",
    "        for batch_ind in range(all_inds.shape[1]):\n",
    "            batch = [self.dataset[int(ind)] for ind in all_inds[:, batch_ind]]\n",
    "            yield self.collate_fn(batch)\n",
    "\n",
    "\n",
    "kwargs = {'pin_memory': True, 'num_workers': 1}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                # sampler=train_sampler,\n",
    "                                collate_fn=collate_fn, **kwargs)\n",
    "\n",
    "valid_dataloader = alignedDataLoader(valid_dataset, batch_size=batch_size, \n",
    "                            # sampler=valid_sampler,\n",
    "                                collate_fn=collate_fn, drop_last=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [train_dataset[i] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(train_dataloader)\n",
    "batch = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(gen)\n",
    "batch = next(gen)\n",
    "batch = next(gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = iter(valid_dataloader)\n",
    "valid_batch = next(valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 108])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  ...,   416,  5609,   511],\n",
       "        [  796,   569, 18354,  ...,  2478,  2233,   284]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  796,   569, 18354,  ...,   416,  5609,   511],\n",
       "        [ 8686,  4282,   764,  ...,  2478,  2233,   284]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:, 1004:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels_mask'][:, 1004:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' = Valkyria Chronicles III = \\n SenjÅ no Valkyria 3 : <unk> Chronicles ( Japanese : æ¦å ´ã®ã´ã¡ã«ã­ã¥ãªã¢3, lit. Valkyria of the Battlefield 3 ), commonly referred to as Valkyria Chronicles III outside Japan, is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable. Released in January 2011 in Japan, it is the third game in the Valkyria series. <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors, the story runs parallel to the first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more <unk> for series newcomers. Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Ozawa. A large team of writers handled the script. The game\\'s opening theme was sung by May \\'n. \\n It met with positive sales in Japan, and was praised by both Japanese and western critics. After release, it received downloadable content, along with an expanded edition in November of that year. It was also adapted into manga and an original video animation series. Due to low sales of Valkyria Chronicles II, Valkyria Chronicles III was not localized, but a fan translation compatible with the game\\'s expanded edition was released in 2014. Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4. \\n = = Gameplay = = \\n As with previous <unk> Chronicles games, Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces. Stories are told through comic book @-@ like panels with animated character portraits, with characters speaking partially through voiced speech bubbles and partially through <unk> text. The player progresses through a series of linear missions, gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked. The route to each story location on the map varies depending on an individual player\\'s approach : when one option is selected, the other is sealed off to the player. Outside missions, the player characters rest in a camp, where units can be customized and character growth occurs. Alongside the main story missions are character @-@ specific sub missions relating to different squad members. After the game\\'s completion, additional episodes are unlocked, some of them having a higher difficulty than those found in the rest of the game. There are also love simulation elements related to the game\\'s two main <unk>, although they take a very minor role. \\n The game\\'s battle system, the <unk> system, is carried over directly from <unk> Chronicles. During missions, players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @-@ person. A character can only act once per @-@ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. Each character has a field and distance of movement limited by their Action <unk>. Up to nine characters can be assigned to a single mission. During gameplay, characters will call out if something happens to them, such as their health points ( HP ) getting low or being knocked out by enemy attacks. Each character has specific \" Potentials \", skills unique to each character. They are divided into \" Personal Potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" Battle Potentials \", which are grown throughout the game and always grant <unk> to a character. To learn Battle Potentials, each character has a unique \" Masters Table \", a grid @-@ based skill table that can be used to acquire and link different skills. Characters also have Special <unk> that grant them temporary <unk> on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without <unk> his Action Point gauge, the character <unk> can shift into her \" Valkyria Form \" and become <unk>, while Imca can target multiple enemy units with her heavy weapon. \\n Troops are divided into five classes : Scouts, <unk>, Engineers, <unk> and Armored Soldier. <unk> can switch classes by changing their'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][:, 1004:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8686, 4282,  764,  ...,  262, 2656,  837],\n",
       "        [ 262, 3859, 1445,  ..., 3670,  373, 7867]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(valid_dataloader)\n",
    "batch = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-@ eastern Atlantic Ocean from northern Norway to the Azores and Morocco, not including the Baltic Sea. It is also present in most of the Mediterranean Sea, only missing from the section east of Crete, and along only the north @-@'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the <unk> and <unk> powers of nearly every one, <unk> their opponents... \\n The side left <unk> and travelled north where they played <unk> in Masterton. The match was won 10 â 8, and'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][1][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' west coast of the Black Sea. The <unk> populations are found in the Norwegian <unk> <unk> and <unk>, inside the Arctic Circle. \\n The species can be divided into four genetically distinct populations, one widespread population,'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the next day they faced Wellington, who they also defeated. The fixture against Wellington was nearly abandoned because Scott and the Wellington Rugby Union could not agree on a venue ; the match went ahead only when the Wellington officials agreed to cede the <unk>'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  796,   569, 18354,  7496, 17740,  6711,   796,   220,   198,  2311])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  796,   569, 18354,  7496, 17740,  6711,   796,   220,   198,  2311])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[796, 569, 18354, 7496, 17740, 6711, 796, 220, 198, 2311]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[796, 569, 18354, 7496, 17740, 6711, 796, 220, 198, 2311]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2008])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' = Valkyria Chronicles III = \\n SenjÅ no Valkyria 3 : <unk> Chronicles ( Japanese : æ¦å ´ã®ã´ã¡ã«ã­ã¥ãªã¢3, lit. Valkyria of the Battlefield 3 ), commonly referred to as Valkyria Chronicles III outside Japan, is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable. Released in January 2011 in Japan, it is the third game in the Valkyria series. <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors, the story runs parallel to the first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more <unk> for series newcomers. Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Ozawa. A large team of writers handled the script. The game\\'s opening theme was sung by May \\'n. \\n It met with positive sales in Japan, and was praised by both Japanese and western critics. After release, it received downloadable content, along with an expanded edition in November of that year. It was also adapted into manga and an original video animation series. Due to low sales of Valkyria Chronicles II, Valkyria Chronicles III was not localized, but a fan translation compatible with the game\\'s expanded edition was released in 2014. Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4. \\n = = Gameplay = = \\n As with previous <unk> Chronicles games, Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces. Stories are told through comic book @-@ like panels with animated character portraits, with characters speaking partially through voiced speech bubbles and partially through <unk> text. The player progresses through a series of linear missions, gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked. The route to each story location on the map varies depending on an individual player\\'s approach : when one option is selected, the other is sealed off to the player. Outside missions, the player characters rest in a camp, where units can be customized and character growth occurs. Alongside the main story missions are character @-@ specific sub missions relating to different squad members. After the game\\'s completion, additional episodes are unlocked, some of them having a higher difficulty than those found in the rest of the game. There are also love simulation elements related to the game\\'s two main <unk>, although they take a very minor role. \\n The game\\'s battle system, the <unk> system, is carried over directly from <unk> Chronicles. During missions, players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected, the player moves the character around the battlefield in third @-@ person. A character can only act once per @-@ turn, but characters can be granted multiple turns at the expense of other characters\\'turns. Each character has a field and distance of movement limited by their Action <unk>. Up to nine characters can be assigned to a single mission. During gameplay, characters will call out if something happens to them, such as their health points ( HP ) getting low or being knocked out by enemy attacks. Each character has specific \" Potentials \", skills unique to each character. They are divided into \" Personal Potential \", which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character, and \" Battle Potentials \", which are grown throughout the game and always grant <unk> to a character. To learn Battle Potentials, each character has a unique \" Masters Table \", a grid @-@ based skill table that can be used to acquire and link different skills. Characters also have Special <unk> that grant them temporary <unk> on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without <unk> his Action Point gauge, the character <unk> can shift into her \" Valkyria Form \" and become <unk>, while Imca can target multiple enemy units with her heavy weapon. \\n Troops are divided into five classes : Scouts, <unk>, Engineers, <unk> and Armored Soldier. <unk> can switch classes by changing their assigned weapon. Changing class does not greatly affect the stats gained while in a previous class. With victory in battle, experience points are awarded to the squad, which are distributed into five different attributes shared by the entire squad, a feature differing from early games\\'method of distributing to different unit types. \\n = = Plot = = \\n The game takes place during the Second Europan War. Gallian Army Squad 422, also known as \" The Nameless \", are a penal military unit composed of criminals, foreign <unk>, and military offenders whose real names are erased from the records and <unk> officially referred to by numbers. <unk> by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do, they are nevertheless up to the task, exemplified by their motto, <unk> <unk>, meaning \" Always Ready. \" The three main characters are <unk> Kurt Irving, an army officer falsely accused of treason who wishes to redeem himself ; Ace <unk> Imca, a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and <unk> Riela <unk>, a seemingly <unk> young woman who is unknowingly a descendant of the Valkyria. Together with their fellow squad members, these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven, consisting of mostly Darcsen soldiers. \\n As the Nameless officially do not exist, the upper echelons of the Gallian Army exploit the concept of plausible <unk> in order to send them on missions that would otherwise make Gallia lose face in the war. While at times this works to their advantage, such as a successful incursion into Imperial territory, other orders cause certain members of the 422nd great distress. One such member, <unk>, becomes so enraged that he abandons his post and defects into the ranks of Calamity Raven, attached to the ideal of Darcsen independence proposed by their leader, Dahau. At the same time, elements within Gallian Army Command move to erase the Nameless in order to protect their own interests. <unk> by both allies and enemies, and combined with the presence of a traitor within their ranks, the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort. This continues until the Nameless\\'s commanding officer, Ramsey Crowe, who had been kept under house arrest, is escorted to the capital city of <unk> in order to present evidence <unk> the weary soldiers and expose the real traitor, the Gallian General that had accused Kurt of Treason. \\n <unk> due to these events, and partly due to the major losses in manpower Gallia suffers towards the end of the war with the Empire, the Nameless are offered a formal position as a squad in the Gallian Army rather than serve as an anonymous shadow force. This is short @-@ lived, however, as following Maximilian\\'s defeat, Dahau and Calamity Raven move to activate an ancient <unk> super weapon within the Empire, kept secret by their benefactor. Without the support of Maximilian or the chance to prove themselves in the war with Gallia, it is Dahau\\'s last <unk> card in creating a new Darcsen nation. As an armed Gallian force invading the Empire just following the two nations\\'cease @-@ fire would certainly wreck their newfound peace, Kurt decides to once again make his squad the Nameless, asking Crowe to list himself and all under his command as killed @-@ in @-@ action. Now owing allegiance to none other than themselves, the 422nd confronts Dahau and destroys the <unk> weapon. Each member then goes their separate ways in order to begin their lives <unk>. \\n = = Development = = \\n Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010, with full development beginning shortly after this. The director of Valkyria Chronicles II, Takeshi Ozawa, returned to that role for Valkyria Chronicles III. Development work took approximately one year. After the release of Valkyria Chronicles II, the staff took a look at both the popular response for the game and what they wanted to do next for the series. Like its predecessor, Valkyria Chronicles III was developed for PlayStation Portable : this was due to the team wanting to refine the mechanics created for Valkyria Chronicles II, and they had not come up with the \" revolutionary \" idea that would warrant a new entry for the PlayStation 3. Speaking in an interview, it was stated that the development team considered Valkyria Chronicles III to be the series\\'first true sequel : while Valkyria Chronicles II had required a large amount of trial and error during development due to'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in valid_dataloader:\n",
    "    if batch['input_ids'].shape[0] != 2:\n",
    "        print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask', 'labels']), torch.Size([2, 1014]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys(), batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bulatov/bulatov/RMT_light/framework/notebooks/debug_rmt_decoder.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpu11/home/bulatov/bulatov/RMT_light/framework/notebooks/debug_rmt_decoder.ipynb#Y206sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m base_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1047\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1047\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1048\u001b[0m     input_ids,\n\u001b[1;32m   1049\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1050\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1051\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1052\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1053\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1054\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1055\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1056\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1057\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1058\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1059\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1060\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1061\u001b[0m )\n\u001b[1;32m   1062\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1064\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:890\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    880\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    881\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    882\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    891\u001b[0m         hidden_states,\n\u001b[1;32m    892\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    893\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    894\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    895\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    896\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    897\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    898\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    899\u001b[0m     )\n\u001b[1;32m    901\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    902\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:432\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    431\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 432\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    433\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[1;32m    434\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:359\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 359\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_fc(hidden_states)\n\u001b[1;32m    360\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[1;32m    361\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(hidden_states)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/cephfs/home/bulatov/bulatov/hvdenv/lib/python3.8/site-packages/transformers/modeling_utils.py:1871\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1869\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m   1870\u001b[0m     size_out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnf,)\n\u001b[0;32m-> 1871\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[1;32m   1872\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(size_out)\n\u001b[1;32m   1873\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = base_model(**batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
